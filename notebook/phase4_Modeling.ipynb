{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uNF78gTOIkRX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_dataset = pd.read_csv('train.csv')\n",
        "test_dataset = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "0Y_uZiBnKFiE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOFb-EzdLOya",
        "outputId": "3573cd0a-50bf-48d9-92a9-06bbdc0170fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
            "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-numeric columns\n",
        "train_dataset = train_dataset.drop(columns=['Name', 'Ticket', 'Cabin'])\n"
      ],
      "metadata": {
        "id": "T0C62XdENAxv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to numeric using one-hot encoding\n",
        "train_dataset = pd.get_dummies(train_dataset, columns=['Sex', 'Embarked'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "b6lQ_O8sND_p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values by filling them with the mean for numerical columns and mode for categorical columns\n",
        "train_dataset['Age'].fillna(train_dataset['Age'].mean(), inplace=True)\n",
        "train_dataset['Fare'].fillna(train_dataset['Fare'].mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "wntlz7IRNHQm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features (X) and target (y)\n",
        "X = train_dataset.drop(columns=['Survived'])  # All columns except 'Survived'\n",
        "y = train_dataset['Survived']  # The target column"
      ],
      "metadata": {
        "id": "glPVbCUbNHM7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Y_JmoL2aNM4G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_logreg = logreg.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_logreg = accuracy_score(y_val, y_pred_logreg)\n",
        "precision_logreg = precision_score(y_val, y_pred_logreg)\n",
        "recall_logreg = recall_score(y_val, y_pred_logreg)\n",
        "f1_logreg = f1_score(y_val, y_pred_logreg)\n",
        "roc_auc_logreg = roc_auc_score(y_val, logreg.predict_proba(X_val)[:, 1])\n",
        "\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(f\"Accuracy: {accuracy_logreg:.4f}\")\n",
        "print(f\"Precision: {precision_logreg:.4f}\")\n",
        "print(f\"Recall: {recall_logreg:.4f}\")\n",
        "print(f\"F1-Score: {f1_logreg:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_logreg:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqAIb_PSIswv",
        "outputId": "e3cfa9ba-b489-4a7d-d0ac-f727b03d7ac3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance:\n",
            "Accuracy: 0.8045\n",
            "Precision: 0.7746\n",
            "Recall: 0.7432\n",
            "F1-Score: 0.7586\n",
            "ROC-AUC: 0.8761\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_dt = dt.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_val, y_pred_dt)\n",
        "precision_dt = precision_score(y_val, y_pred_dt)\n",
        "recall_dt = recall_score(y_val, y_pred_dt)\n",
        "f1_dt = f1_score(y_val, y_pred_dt)\n",
        "roc_auc_dt = roc_auc_score(y_val, dt.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"Decision Tree Performance:\")\n",
        "print(f\"Accuracy: {accuracy_dt:.4f}\")\n",
        "print(f\"Precision: {precision_dt:.4f}\")\n",
        "print(f\"Recall: {recall_dt:.4f}\")\n",
        "print(f\"F1-Score: {f1_dt:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_dt:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe6lwtpuIsuG",
        "outputId": "d08afa64-b350-4f3a-8fd8-eec48a2671cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Performance:\n",
            "Accuracy: 0.7542\n",
            "Precision: 0.7083\n",
            "Recall: 0.6892\n",
            "F1-Score: 0.6986\n",
            "ROC-AUC: 0.7446\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_rf = rf.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
        "precision_rf = precision_score(y_val, y_pred_rf)\n",
        "recall_rf = recall_score(y_val, y_pred_rf)\n",
        "f1_rf = f1_score(y_val, y_pred_rf)\n",
        "roc_auc_rf = roc_auc_score(y_val, rf.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"Random Forest Performance:\")\n",
        "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1-Score: {f1_rf:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_rf:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Td0KJDIsrg",
        "outputId": "992c5978-1272-4e7e-efcc-df0a4ebcf449"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Performance:\n",
            "Accuracy: 0.8324\n",
            "Precision: 0.8333\n",
            "Recall: 0.7432\n",
            "F1-Score: 0.7857\n",
            "ROC-AUC: 0.8894\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize SVM model\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_svm = svm.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
        "precision_svm = precision_score(y_val, y_pred_svm)\n",
        "recall_svm = recall_score(y_val, y_pred_svm)\n",
        "f1_svm = f1_score(y_val, y_pred_svm)\n",
        "roc_auc_svm = roc_auc_score(y_val, svm.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"Support Vector Machine Performance:\")\n",
        "print(f\"Accuracy: {accuracy_svm:.4f}\")\n",
        "print(f\"Precision: {precision_svm:.4f}\")\n",
        "print(f\"Recall: {recall_svm:.4f}\")\n",
        "print(f\"F1-Score: {f1_svm:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_svm:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB6a8aVGIsmi",
        "outputId": "ef7c9909-19d9-416b-8539-e6df122a2b54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine Performance:\n",
            "Accuracy: 0.5978\n",
            "Precision: 0.6667\n",
            "Recall: 0.0541\n",
            "F1-Score: 0.1000\n",
            "ROC-AUC: 0.7416\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize GBM model\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_gbm = gbm.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_gbm = accuracy_score(y_val, y_pred_gbm)\n",
        "precision_gbm = precision_score(y_val, y_pred_gbm)\n",
        "recall_gbm = recall_score(y_val, y_pred_gbm)\n",
        "f1_gbm = f1_score(y_val, y_pred_gbm)\n",
        "roc_auc_gbm = roc_auc_score(y_val, gbm.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"Gradient Boosting Machine Performance:\")\n",
        "print(f\"Accuracy: {accuracy_gbm:.4f}\")\n",
        "print(f\"Precision: {precision_gbm:.4f}\")\n",
        "print(f\"Recall: {recall_gbm:.4f}\")\n",
        "print(f\"F1-Score: {f1_gbm:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_gbm:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyaSMioXI1IH",
        "outputId": "13e42a74-f566-4da1-a1c3-f6f0fc62e999"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Machine Performance:\n",
            "Accuracy: 0.8156\n",
            "Precision: 0.8060\n",
            "Recall: 0.7297\n",
            "F1-Score: 0.7660\n",
            "ROC-AUC: 0.8712\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_rf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_rf,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters for Random Forest:\")\n",
        "print(grid_rf.best_params_)\n",
        "\n",
        "# Best estimator\n",
        "best_rf = grid_rf.best_estimator_\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_best_rf = best_rf.predict(X_val)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "accuracy_best_rf = accuracy_score(y_val, y_pred_best_rf)\n",
        "precision_best_rf = precision_score(y_val, y_pred_best_rf)\n",
        "recall_best_rf = recall_score(y_val, y_pred_best_rf)\n",
        "f1_best_rf = f1_score(y_val, y_pred_best_rf)\n",
        "roc_auc_best_rf = roc_auc_score(y_val, best_rf.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"\\nTuned Random Forest Performance:\")\n",
        "print(f\"Accuracy: {accuracy_best_rf:.4f}\")\n",
        "print(f\"Precision: {precision_best_rf:.4f}\")\n",
        "print(f\"Recall: {recall_best_rf:.4f}\")\n",
        "print(f\"F1-Score: {f1_best_rf:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_best_rf:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K559Rv2I1Fk",
        "outputId": "15cb8920-92b1-49af-ef72-872974c34267"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters for Random Forest:\n",
            "{'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "\n",
            "Tuned Random Forest Performance:\n",
            "Accuracy: 0.8156\n",
            "Precision: 0.8254\n",
            "Recall: 0.7027\n",
            "F1-Score: 0.7591\n",
            "ROC-AUC: 0.8915\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter grid\n",
        "param_grid_gbm = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_gbm = GridSearchCV(\n",
        "    estimator=GradientBoostingClassifier(random_state=42),\n",
        "    param_grid=param_grid_gbm,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_gbm.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters for GBM:\")\n",
        "print(grid_gbm.best_params_)\n",
        "\n",
        "# Best estimator\n",
        "best_gbm = grid_gbm.best_estimator_\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred_best_gbm = best_gbm.predict(X_val)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "accuracy_best_gbm = accuracy_score(y_val, y_pred_best_gbm)\n",
        "precision_best_gbm = precision_score(y_val, y_pred_best_gbm)\n",
        "recall_best_gbm = recall_score(y_val, y_pred_best_gbm)\n",
        "f1_best_gbm = f1_score(y_val, y_pred_best_gbm)\n",
        "roc_auc_best_gbm = roc_auc_score(y_val, best_gbm.predict_proba(X_val)[:,1])\n",
        "\n",
        "print(\"\\nTuned GBM Performance:\")\n",
        "print(f\"Accuracy: {accuracy_best_gbm:.4f}\")\n",
        "print(f\"Precision: {precision_best_gbm:.4f}\")\n",
        "print(f\"Recall: {recall_best_gbm:.4f}\")\n",
        "print(f\"F1-Score: {f1_best_gbm:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_best_gbm:.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvm5s4h_I1C7",
        "outputId": "6bafb07e-07e7-413d-fef2-dd1f3cfa2ef0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "Best Parameters for GBM:\n",
            "{'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "\n",
            "Tuned GBM Performance:\n",
            "Accuracy: 0.8156\n",
            "Precision: 0.8060\n",
            "Recall: 0.7297\n",
            "F1-Score: 0.7660\n",
            "ROC-AUC: 0.8712\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model performances\n",
        "models = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'SVM', 'GBM', 'Tuned Random Forest', 'Tuned GBM']\n",
        "accuracies = [accuracy_logreg, accuracy_dt, accuracy_rf, accuracy_svm, accuracy_gbm, accuracy_best_rf, accuracy_best_gbm]\n",
        "precisions = [precision_logreg, precision_dt, precision_rf, precision_svm, precision_gbm, precision_best_rf, precision_best_gbm]\n",
        "recalls = [recall_logreg, recall_dt, recall_rf, recall_svm, recall_gbm, recall_best_rf, recall_best_gbm]\n",
        "f1_scores = [f1_logreg, f1_dt, f1_rf, f1_svm, f1_gbm, f1_best_rf, f1_best_gbm]\n",
        "roc_aucs = [roc_auc_logreg, roc_auc_dt, roc_auc_rf, roc_auc_svm, roc_auc_gbm, roc_auc_best_rf, roc_auc_best_gbm]\n",
        "\n",
        "performance_df = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'Accuracy': accuracies,\n",
        "    'Precision': precisions,\n",
        "    'Recall': recalls,\n",
        "    'F1-Score': f1_scores,\n",
        "    'ROC-AUC': roc_aucs\n",
        "})\n",
        "\n",
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(performance_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yVy0Q0VI-c3",
        "outputId": "392e6396-4a6c-4529-fea4-2d0561c0c229"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance Comparison:\n",
            "                 Model  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
            "0  Logistic Regression  0.804469   0.774648  0.743243  0.758621  0.876062\n",
            "1        Decision Tree  0.754190   0.708333  0.689189  0.698630  0.744595\n",
            "2        Random Forest  0.832402   0.833333  0.743243  0.785714  0.889447\n",
            "3                  SVM  0.597765   0.666667  0.054054  0.100000  0.741570\n",
            "4                  GBM  0.815642   0.805970  0.729730  0.765957  0.871236\n",
            "5  Tuned Random Forest  0.815642   0.825397  0.702703  0.759124  0.891506\n",
            "6            Tuned GBM  0.815642   0.805970  0.729730  0.765957  0.871236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the model with the highest ROC-AUC\n",
        "best_model_index = performance_df['ROC-AUC'].idxmax()\n",
        "best_model = performance_df.loc[best_model_index, 'Model']\n",
        "\n",
        "print(f\"\\nBest Performing Model: {best_model}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CbXdYg2I-aN",
        "outputId": "abfe20eb-fe92-4083-a60e-c377ddf45f80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Performing Model: Tuned Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the 'models' directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n"
      ],
      "metadata": {
        "id": "3nLutLTsin8H"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_rf, 'models/best_model.pkl')\n",
        "\n",
        "print(\"Best model saved as 'models/best_model.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WjfRTqfj_n_",
        "outputId": "8554a6ad-095a-4883-8302-7b6117c5e0a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved as 'models/best_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('models'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqKsR8wUCPlO",
        "outputId": "24b05984-b4d6-4f84-e8a0-d5e09e955eeb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['best_model.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path in Google Drive\n",
        "model_drive_path = '/content/drive/MyDrive/models/best_model.pkl'\n",
        "\n",
        "# Save the model to Google Drive\n",
        "joblib.dump(best_rf, model_drive_path)\n",
        "\n",
        "print(f\"Best model saved to Google Drive at '{model_drive_path}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wloeRbrcCVaw",
        "outputId": "791532ea-5996-4aeb-91af-74ff3ea6de35"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Best model saved to Google Drive at '/content/drive/MyDrive/models/best_model.pkl'\n"
          ]
        }
      ]
    }
  ]
}